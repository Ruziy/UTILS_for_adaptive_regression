{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb644ae0",
   "metadata": {},
   "source": [
    "### –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö, –±–µ–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ (—Ç.–∫. –í–°–Ø –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–Ø –ü–û–î –ö–ê–ü–û–¢–û–ú)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cc0163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(r\"C:\\Users\\Alex\\Desktop\\STAY_SMARTER\\adaptive_ARC\\data\\3d_print_train.csv\")\n",
    "test_df = pd.read_csv(r\"C:\\Users\\Alex\\Desktop\\STAY_SMARTER\\adaptive_ARC\\data\\3d_print_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bac56b",
   "metadata": {},
   "source": [
    "### Learn (–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ 1 –ø—Ä–∏–∑–Ω–∞–∫ ->MonoRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f20888a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels\\model_height\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       15.05 GB / 31.90 GB (47.2%)\n",
      "Disk Space Avail:   79.27 GB / 930.87 GB (8.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è \"height\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"c:\\Users\\Alex\\Desktop\\–†–ê–ó–í–ò–í–ê–ô–°–Ø –ò–î–ò–û–¢\\adaptive_ARC\\ML_adaptive\\AutogluonModels\\model_height\"\n",
      "Train Data Rows:    295\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    5\n",
      "Tuning Data Columns: 7\n",
      "Label Column:       height\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15405.06 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.08 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 2 | ['layer_height', 'width']\n",
      "\t\t('int', [])    : 1 | ['infill_density']\n",
      "\t\t('object', []) : 4 | ['shape_type', 'material', 'color', 'print_quality']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 4 | ['shape_type', 'material', 'color', 'print_quality']\n",
      "\t\t('float', [])    : 2 | ['layer_height', 'width']\n",
      "\t\t('int', [])      : 1 | ['infill_density']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 299.92s of the 299.92s of remaining time.\n",
      "\t-2.6768\t = Validation score   (-mean_absolute_error)\n",
      "\t2.32s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 297.56s of the 297.56s of remaining time.\n",
      "\t-0.6591\t = Validation score   (-mean_absolute_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 297.53s of the 297.53s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 1.84205\n",
      "[2000]\tvalid_set's l1: 1.50964\n",
      "[3000]\tvalid_set's l1: 1.25372\n",
      "[4000]\tvalid_set's l1: 1.11091\n",
      "[5000]\tvalid_set's l1: 1.01586\n",
      "[6000]\tvalid_set's l1: 0.933678\n",
      "[7000]\tvalid_set's l1: 0.881597\n",
      "[8000]\tvalid_set's l1: 0.830305\n",
      "[9000]\tvalid_set's l1: 0.786371\n",
      "[10000]\tvalid_set's l1: 0.753012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.7528\t = Validation score   (-mean_absolute_error)\n",
      "\t2.17s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 295.00s of the 295.00s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 0.308589\n",
      "[2000]\tvalid_set's l1: 0.247795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.2392\t = Validation score   (-mean_absolute_error)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 294.42s of the 294.42s of remaining time.\n",
      "\t-1.0635\t = Validation score   (-mean_absolute_error)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 293.72s of the 293.72s of remaining time.\n",
      "\t-1.1994\t = Validation score   (-mean_absolute_error)\n",
      "\t200.47s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 93.22s of the 93.22s of remaining time.\n",
      "\t-1.1085\t = Validation score   (-mean_absolute_error)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 92.65s of the 92.65s of remaining time.\n",
      "\t-16.2317\t = Validation score   (-mean_absolute_error)\n",
      "\t1.74s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 90.87s of the 90.87s of remaining time.\n",
      "\t-0.4818\t = Validation score   (-mean_absolute_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 90.44s of the 90.44s of remaining time.\n",
      "\t-0.351\t = Validation score   (-mean_absolute_error)\n",
      "\t24.08s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 66.34s of the 66.34s of remaining time.\n",
      "\t-0.2897\t = Validation score   (-mean_absolute_error)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.92s of the 65.74s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM': 0.625, 'CatBoost': 0.208, 'XGBoost': 0.167}\n",
      "\t-0.1829\t = Validation score   (-mean_absolute_error)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 234.38s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 277.8 rows/s (5 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\Alex\\Desktop\\–†–ê–ó–í–ò–í–ê–ô–°–Ø –ò–î–ò–û–¢\\adaptive_ARC\\ML_adaptive\\AutogluonModels\\model_height\")\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       14.92 GB / 31.90 GB (46.8%)\n",
      "Disk Space Avail:   79.19 GB / 930.87 GB (8.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"c:\\Users\\Alex\\Desktop\\–†–ê–ó–í–ò–í–ê–ô–°–Ø –ò–î–ò–û–¢\\adaptive_ARC\\ML_adaptive\\AutogluonModels\\model_width\"\n",
      "Train Data Rows:    295\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    5\n",
      "Tuning Data Columns: 7\n",
      "Label Column:       width\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15275.84 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.08 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 2 | ['layer_height', 'height']\n",
      "\t\t('int', [])    : 1 | ['infill_density']\n",
      "\t\t('object', []) : 4 | ['shape_type', 'material', 'color', 'print_quality']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 4 | ['shape_type', 'material', 'color', 'print_quality']\n",
      "\t\t('float', [])    : 2 | ['layer_height', 'height']\n",
      "\t\t('int', [])      : 1 | ['infill_density']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 299.92s of the 299.92s of remaining time.\n",
      "\t-1.6334\t = Validation score   (-mean_absolute_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 299.89s of the 299.89s of remaining time.\n",
      "\t-0.4215\t = Validation score   (-mean_absolute_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 299.86s of the 299.86s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è \"width\"\n",
      "[1000]\tvalid_set's l1: 0.597849\n",
      "[2000]\tvalid_set's l1: 0.433598\n",
      "[3000]\tvalid_set's l1: 0.378083\n",
      "[4000]\tvalid_set's l1: 0.324208\n",
      "[5000]\tvalid_set's l1: 0.28537\n",
      "[6000]\tvalid_set's l1: 0.256658\n",
      "[7000]\tvalid_set's l1: 0.250573\n",
      "[8000]\tvalid_set's l1: 0.240757\n",
      "[9000]\tvalid_set's l1: 0.231145\n",
      "[10000]\tvalid_set's l1: 0.224282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.2217\t = Validation score   (-mean_absolute_error)\n",
      "\t1.44s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 298.05s of the 298.05s of remaining time.\n",
      "\t-0.3754\t = Validation score   (-mean_absolute_error)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 297.82s of the 297.82s of remaining time.\n",
      "\t-0.4634\t = Validation score   (-mean_absolute_error)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 297.27s of the 297.27s of remaining time.\n",
      "\t-0.7364\t = Validation score   (-mean_absolute_error)\n",
      "\t27.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 269.98s of the 269.97s of remaining time.\n",
      "\t-0.6218\t = Validation score   (-mean_absolute_error)\n",
      "\t0.44s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 269.46s of the 269.46s of remaining time.\n",
      "\t-14.7607\t = Validation score   (-mean_absolute_error)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 268.92s of the 268.91s of remaining time.\n",
      "\t-0.2715\t = Validation score   (-mean_absolute_error)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 268.73s of the 268.73s of remaining time.\n",
      "\t-3.3736\t = Validation score   (-mean_absolute_error)\n",
      "\t0.86s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 267.86s of the 267.86s of remaining time.\n",
      "\t-0.3067\t = Validation score   (-mean_absolute_error)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.92s of the 267.32s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT': 1.0}\n",
      "\t-0.2217\t = Validation score   (-mean_absolute_error)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 32.78s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 767.1 rows/s (5 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\Alex\\Desktop\\–†–ê–ó–í–ò–í–ê–ô–°–Ø –ò–î–ò–û–¢\\adaptive_ARC\\ML_adaptive\\AutogluonModels\\model_width\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä MAE –ø–æ –∫–∞–∂–¥–æ–º—É —Ç–∞—Ä–≥–µ—Ç—É:\n",
      "height: -0.2664\n",
      "width: -0.3391\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "import os\n",
    "\n",
    "results = {}\n",
    "models = {}\n",
    "\n",
    "base_path = 'AutogluonModels'\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "for label in ['height', 'width']:\n",
    "    print(f'\\nüîß –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è \"{label}\"')\n",
    "    \n",
    "    model_path = os.path.join(base_path, f'model_{label}')\n",
    "    predictor = TabularPredictor(\n",
    "        label=label,\n",
    "        problem_type='regression',\n",
    "        eval_metric='mean_absolute_error',\n",
    "        path=model_path\n",
    "    )\n",
    "    \n",
    "    predictor.fit(\n",
    "    train_data=train_df.copy(),\n",
    "    tuning_data=test_df.copy(),  \n",
    "    time_limit=300\n",
    ")\n",
    "    \n",
    "    mae = predictor.evaluate(train_df)[f'mean_absolute_error']\n",
    "    results[label] = mae\n",
    "    models[label] = predictor\n",
    "\n",
    "print(\"\\nüìä MAE –ø–æ –∫–∞–∂–¥–æ–º—É —Ç–∞—Ä–≥–µ—Ç—É:\")\n",
    "for label, mae in results.items():\n",
    "    print(f\"{label}: {mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5172c932",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dafa5c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "predictor_height = TabularPredictor.load(\"AutogluonModels/model_height\")\n",
    "predictor_width = TabularPredictor.load(\"AutogluonModels/model_width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e4afc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  model model_type_general  mae_height  mae_width    mae_avg\n",
      "10  WeightedEnsemble_L2           Ensemble    0.182941   0.221698   0.202320\n",
      "5         LightGBMLarge                 ML    0.289728   0.306694   0.298211\n",
      "4              LightGBM                 ML    0.239180   0.375437   0.307309\n",
      "11              XGBoost                 ML    0.481769   0.271513   0.376641\n",
      "6            LightGBMXT                 ML    0.752775   0.221698   0.487237\n",
      "2        KNeighborsDist                 ML    0.659085   0.421502   0.540293\n",
      "9       RandomForestMSE                 ML    1.063468   0.463358   0.763413\n",
      "1         ExtraTreesMSE                 ML    1.108545   0.621846   0.865196\n",
      "0              CatBoost                 ML    1.199369   0.736420   0.967895\n",
      "8        NeuralNetTorch                 DL    0.351011   3.373639   1.862325\n",
      "3        KNeighborsUnif                 ML    2.676799   1.633358   2.155078\n",
      "7       NeuralNetFastAI                 DL   16.231724  14.760704  15.496214\n"
     ]
    }
   ],
   "source": [
    "lb_h = predictor_height.leaderboard(silent=True)\n",
    "lb_w = predictor_width.leaderboard(silent=True)\n",
    "\n",
    "lb_h = lb_h[['model', 'score_val']].rename(columns={'score_val': 'mae_height'})\n",
    "lb_w = lb_w[['model', 'score_val']].rename(columns={'score_val': 'mae_width'})\n",
    "\n",
    "merged = pd.merge(lb_h, lb_w, on='model', how='outer')\n",
    "\n",
    "merged['mae_height'] = merged['mae_height'].abs()\n",
    "merged['mae_width'] = merged['mae_width'].abs()\n",
    "merged['mae_avg'] = (merged['mae_height'] + merged['mae_width']) / 2\n",
    "\n",
    "meta = predictor_height.leaderboard(silent=True)[['model', 'fit_time', 'pred_time_val', 'stack_level']]\n",
    "final = pd.merge(merged, meta, on='model', how='left')\n",
    "\n",
    "def get_model_type_general(model_name):\n",
    "    if model_name.startswith('NeuralNet'):\n",
    "        return 'DL'\n",
    "    elif model_name.startswith('WeightedEnsemble'):\n",
    "        return 'Ensemble' \n",
    "    else:\n",
    "        return 'ML'\n",
    "    \n",
    "final['model_type_general'] = final['model'].apply(get_model_type_general)\n",
    "\n",
    "\n",
    "print(final.sort_values('mae_avg')[['model', 'model_type_general', 'mae_height', 'mae_width', 'mae_avg']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4151ae8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 model  score_val\n",
      "0  WeightedEnsemble_L2  -0.182941\n",
      "1             LightGBM  -0.239180\n",
      "2        LightGBMLarge  -0.289728\n",
      "3       NeuralNetTorch  -0.351011\n",
      "4              XGBoost  -0.481769\n",
      "                 model  score_val\n",
      "0           LightGBMXT  -0.221698\n",
      "1  WeightedEnsemble_L2  -0.221698\n",
      "2              XGBoost  -0.271513\n",
      "3        LightGBMLarge  -0.306694\n",
      "4             LightGBM  -0.375437\n"
     ]
    }
   ],
   "source": [
    "print(predictor_height.leaderboard(silent=True)[['model','score_val']].head())\n",
    "print(predictor_width.leaderboard(silent=True)[['model','score_val']].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opk_MCD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
